# -*- coding: utf-8 -*-
"""10test_appweb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/165cvgDfoEkhuuoIjGh-avi81XU-bJF8X

# Instalación de paquetes
"""

#!pip install pdf2image
#!apt-get install poppler-utils -y
#!pip install pytesseract
#!sudo apt update
#!sudo apt install tesseract-ocr -y
#!pip install easyocr

import re

pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"
import pytesseract
from pdf2image import convert_from_path
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
import easyocr

"""# Primera página

## Funciones para procesar como tabla:
"""

def sort_cells(cnts, vertical_thresh=30):

    bounding_boxes = [cv2.boundingRect(c) for c in cnts]
    bounding_boxes = sorted(bounding_boxes, key=lambda b: b[1])  # Ordena todos los bounding boxes por coordenada y (posición vertical), es decir, de arriba hacia abajo.

    rows = [] # rows: lista final con filas ordenadas
    current_row = [] # current_row: la fila que se está construyendo
    last_y = None #last_y: para comparar si una caja pertenece a la misma fila
    #threshold: tolerancia para decidir si dos cajas están en la misma fila

    for box in bounding_boxes:
      #itera sobre cada bounding box ya ordenado por y.
        x, y, w, h = box
        if last_y is None:
            current_row.append(box)
            last_y = y
            continue
        if abs(y - last_y) < vertical_thresh: # Si la diferencia vertical es muy grande, se asume que es una nueva fila:
            current_row.append(box)
        else:
            rows.append(sorted(current_row, key=lambda b: b[0]))  # Se guarda la fila actual ordenada horizontalmente
            current_row = [box]

        last_y = y # Actualiza last_y con la posición de la celda actual.

    if current_row:
        rows.append(sorted(current_row, key=lambda b: b[0])) # añade la última fila construida (si existe).

    # Verificar resultado
    #print(f"Total filas detectadas: {len(rows)}")
    #for i, row in enumerate(rows):
     #   print(f"  Fila {i + 1}: {len(row)} celdas")

    return [cell for row in rows for cell in row] # Devuelve una lista "aplanada" con todas las celdas, ordenadas primero por fila, luego por columna.

"""## Auxiliares"""

# --- Agrupar líneas similares ---
def agrupar_lineas_similares(lineas, tolerancia=15, orientacion="horizontal"):
    if not lineas:
        return []
    key = 1 if orientacion == "horizontal" else 0
    lineas = sorted(lineas, key=lambda l: l[0][key])
    agrupadas = []
    actual = lineas[0]

    for siguiente in lineas[1:]:
        if abs(siguiente[0][key] - actual[0][key]) < tolerancia:
            actual = np.vstack((actual, siguiente))
        else:
            agrupadas.append(actual)
            actual = siguiente

    agrupadas.append(actual)

    unificadas = []
    for grupo in agrupadas:
        grupo_np = np.array(grupo)
        xs = grupo_np[:, 0]
        ys = grupo_np[:, 1]
        x1, x2 = min(xs), max(xs)
        y1, y2 = min(ys), max(ys)
        if orientacion == "horizontal":
            unificadas.append([(x1, int(np.mean(ys))), (x2, int(np.mean(ys)))])
        else:
            unificadas.append([(int(np.mean(xs)), y1), (int(np.mean(xs)), y2)])

    return unificadas

# --- Filtrar líneas con vecinas ---
def filtrar_lineas_con_vecinas(lineas, orientacion="horizontal", tolerancia=30, min_vecinas=1):
    if not lineas:
        return []
    resultado = []
    posiciones = [l[0][1] if orientacion == "horizontal" else l[0][0] for l in lineas]

    for i, linea in enumerate(lineas):
        pos = posiciones[i]
        vecinas = [1 for j, otra_pos in enumerate(posiciones) if i != j and abs(otra_pos - pos) < tolerancia]
        if len(vecinas) >= min_vecinas:
            resultado.append(linea)
    return resultado

# --- Validación cruzada entre horizontales y verticales ---
def filtrar_lineas_cruzadas(horizontales, verticales, tolerancia=30):
    horizontales_validas = []
    verticales_validas = []

    for h in horizontales:
        (hx1, hy), (hx2, _) = h
        for v in verticales:
            (vx, vy1), (_, vy2) = v
            if (hx1 - tolerancia) <= vx <= (hx2 + tolerancia) and (vy1 <= hy <= vy2):
                horizontales_validas.append(h)
                break

    for v in verticales:
        (vx, vy1), (_, vy2) = v
        for h in horizontales:
            (hx1, hy), (hx2, _) = h
            if (hx1 <= vx <= hx2) and (vy1 - tolerancia <= hy <= vy2 + tolerancia):
                verticales_validas.append(v)
                break

    return horizontales_validas, verticales_validas

from sklearn.cluster import DBSCAN
import numpy as np

def detectar_cuadricula_densa(cell_boxes, eps=50, min_samples=10):
    """
    Agrupa celdas cercanas y detecta una posible tabla 5x5.

    cell_boxes: lista de (x, y, w, h) celdas
    eps: distancia máxima entre vecinos
    min_samples: mínimo número de celdas en el grupo

    Retorna:
        grupo_celdas: celdas que forman la tabla densa
        bbox: (x_min, y_min, x_max, y_max)
    """
    if len(cell_boxes) == 0:
        return [], None

    # Usar los centros de las celdas para agrupar
    centros = np.array([[x + w//2, y + h//2] for x, y, w, h in cell_boxes])
    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(centros)
    etiquetas = clustering.labels_

    grupos = {}
    for idx, etiqueta in enumerate(etiquetas):
        if etiqueta == -1:
            continue
        grupos.setdefault(etiqueta, []).append(cell_boxes[idx])

    mejor_grupo = []
    for g in grupos.values():
        if 20 <= len(g) <= 30:
            mejor_grupo = g
            break

    if not mejor_grupo:
        return [], None

    xs = [x for x, y, w, h in mejor_grupo] + [x + w for x, y, w, h in mejor_grupo]
    ys = [y for x, y, w, h in mejor_grupo] + [y + h for x, y, w, h in mejor_grupo]
    return mejor_grupo, (min(xs), min(ys), max(xs), max(ys))

"""## Obtener primera tabla, primera página"""

def obtener_primera_tabla(image, rotation=270):
    """
    Procesa una imagen para detectar y resaltar la cuadrícula de una tabla,
    realizando el recorte dinámicamente con base en líneas horizontales y verticales.

    Retorna:
        grid : imagen binaria de la cuadrícula detectada.
        t : imagen recortada de la tabla con celdas numeradas.
        gray : imagen en escala de grises de la tabla.
        sorted_cells_f : celdas ordenadas (x, y, w, h).
    """
    image = image.rotate(rotation, expand=True)
    image_cv = np.array(image)
    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)
    gray_full = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)

    _, binary = cv2.threshold(gray_full, 150, 255, cv2.THRESH_BINARY_INV)
    bordes = cv2.Canny(binary, 50, 150, apertureSize=3)
    lineas = cv2.HoughLinesP(bordes, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=20)

    horizontales, verticales = [], []
    if lineas is not None:
        for linea in lineas:
            x1, y1, x2, y2 = linea[0]
            if abs(y2 - y1) < 15:
                horizontales.append([(x1, y1), (x2, y2)])
            elif abs(x2 - x1) < 15:
                verticales.append([(x1, y1), (x2, y2)])

    horizontales_f = filtrar_lineas_con_vecinas(horizontales, "horizontal", 30, 1)
    verticales_f = filtrar_lineas_con_vecinas(verticales, "vertical", 30, 1)

    horizontales_u = agrupar_lineas_similares(horizontales_f, orientacion="horizontal")
    verticales_u = agrupar_lineas_similares(verticales_f, orientacion="vertical")

    # 🔄 Extender horizontales al ancho detectado
    if verticales_u:
        xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
        left, right = min(xs), max(xs)
        horizontales_u = [[(left, y1), (right, y2)] for (x1, y1), (x2, y2) in horizontales_u]

    # 🔁 Validación cruzada
    horizontales_u, verticales_u = filtrar_lineas_cruzadas(horizontales_u, verticales_u, 30)

    # 🔄 Extensión de verticales exteriores
    if verticales_u and horizontales_u:
        ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
        min_y = min(ys)
        max_y = max(ys)

        xs = [v[0][0] for v in verticales_u]
        min_x = min(xs)
        max_x = max(xs)

        verticales_extendidas = []
        for (x1, y1), (x2, y2) in verticales_u:
            if x1 == min_x or x1 == max_x:
                nueva_y1 = max(min_y - 100, 0)
                nueva_y2 = max_y + 100
                verticales_extendidas.append([(x1, nueva_y1), (x2, nueva_y2)])
            else:
                verticales_extendidas.append([(x1, y1), (x2, y2)])
        verticales_u = verticales_extendidas

    if not horizontales_u or not verticales_u:
        print("No se detectó un contorno rectangular válido.")
        return None, None, None, None

    ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
    xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
    top, bottom = min(ys), max(ys)
    left, right = min(xs), max(xs)

    tabla_recortada_aux = image_cv[top:bottom, left:right].copy()

    x1, x2 = 650, 1970
    y1, y2 = 950, 1400
    h_aux, w_aux, _ = tabla_recortada_aux.shape
    if x2 > w_aux or y2 > h_aux:
        raise ValueError(f"Las coordenadas de recorte están fuera de la tabla: ancho={w_aux}, alto={h_aux}")

    tabla_recortada = tabla_recortada_aux[y1:y2, x1:x2].copy()
    gray = cv2.cvtColor(tabla_recortada, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)
    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8), iterations=1)

    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 30))
    horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)
    vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)

    h_lines_extended = np.zeros_like(horizontal_lines)
    v_lines_extended = np.zeros_like(vertical_lines)
    alto_tabla, ancho_tabla = horizontal_lines.shape

    contours_h, _ = cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_h:
        x, y, w, h = cv2.boundingRect(cnt)
        y_center = y + h // 2
        cv2.line(h_lines_extended, (0, y_center), (ancho_tabla - 1, y_center), 255, 1)

    contours_v, _ = cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_v:
        x, y, w, h = cv2.boundingRect(cnt)
        x_center = x + w // 2
        cv2.line(v_lines_extended, (x_center, 0), (x_center, alto_tabla - 1), 255, 1)

    grid = cv2.bitwise_or(h_lines_extended, v_lines_extended)
    grid = cv2.dilate(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=5)
    grid = cv2.erode(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = np.vstack([grid, np.full((3, grid.shape[1]), 255, dtype=np.uint8)])

    contours_f, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours_f = [cnt for cnt in contours_f if cv2.contourArea(cnt) > 2500]
    sorted_cells_f = sort_cells(cell_contours_f)

    grupo_denso, bbox = detectar_cuadricula_densa(sorted_cells_f)

    if grupo_denso:
        x1, y1, x2, y2 = bbox
        tabla_detectada = tabla_recortada[y1:y2, x1:x2]
        # Aquí puedes extraer solo esa tabla (la 5x5)

    for idx, (cx, cy, cw, ch) in enumerate(sorted_cells_f):
        cv2.putText(tabla_recortada, str(idx), (cx+3, cy+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    cv2.drawContours(tabla_recortada, contours_f, -1, (0, 255, 0), 2)

    return grid, tabla_recortada, gray, sorted_cells_f, tabla_recortada_aux

"""## Obtener segunda tabla, primera página

Incluir que calcule el número de contornos y si no los encuentra, que aumente en X el valor
"""

def obtener_segunda_tabla(image, rotation=270):
    """
    Procesa una imagen para detectar y resaltar la cuadrícula de una tabla,
    realizando el recorte dinámicamente con base en líneas horizontales y verticales.

    Retorna:
        grid : imagen binaria de la cuadrícula detectada.
        t : imagen recortada de la tabla con celdas numeradas.
        gray : imagen en escala de grises de la tabla.
        sorted_cells_f : celdas ordenadas (x, y, w, h).
    """
    image = image.rotate(rotation, expand=True)

    image_cv = np.array(image)
    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)
    gray_full = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)

    _, binary = cv2.threshold(gray_full, 150, 255, cv2.THRESH_BINARY_INV)
    bordes = cv2.Canny(binary, 50, 150, apertureSize=3)

    lineas = cv2.HoughLinesP(bordes, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=20)
    horizontales, verticales = [], []

    if lineas is not None:
        for linea in lineas:
            x1, y1, x2, y2 = linea[0]
            if abs(y2 - y1) < 15:
                horizontales.append([(x1, y1), (x2, y2)])
            elif abs(x2 - x1) < 15:
                verticales.append([(x1, y1), (x2, y2)])

    horizontales_f = filtrar_lineas_con_vecinas(horizontales, "horizontal", 30, 1)
    verticales_f = filtrar_lineas_con_vecinas(verticales, "vertical", 30, 1)

    horizontales_u = agrupar_lineas_similares(horizontales_f, orientacion="horizontal")
    verticales_u = agrupar_lineas_similares(verticales_f, orientacion="vertical")

    if verticales_u:
        xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
        left, right = min(xs), max(xs)
        horizontales_u = [[(left, y1), (right, y2)] for (x1, y1), (x2, y2) in horizontales_u]

    horizontales_u, verticales_u = filtrar_lineas_cruzadas(horizontales_u, verticales_u, 30)

    # 🔄 Extender líneas verticales exteriores hacia arriba y abajo 100 píxeles
    if verticales_u and horizontales_u:
        ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
        min_y = min(ys)
        max_y = max(ys)

        xs = [v[0][0] for v in verticales_u]
        min_x = min(xs)
        max_x = max(xs)

        verticales_extendidas = []
        for (x1, y1), (x2, y2) in verticales_u:
            if x1 == min_x or x1 == max_x:
                nueva_y1 = max(min_y - 100, 0)
                nueva_y2 = max_y + 100
                verticales_extendidas.append([(x1, nueva_y1), (x2, nueva_y2)])
            else:
                verticales_extendidas.append([(x1, y1), (x2, y2)])
        verticales_u = verticales_extendidas

    if not horizontales_u or not verticales_u:
        print("No se detectó un contorno rectangular válido.")
        return None, None, None, None

    ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
    xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
    top, bottom = min(ys), max(ys)
    left, right = min(xs), max(xs)

    tabla_recortada_aux = image_cv[top:bottom, left:right].copy()

    x1, x2 = 530, 2100   # columnas (ancho)
    y1, y2 = 1600, 2200   # filas (alto)

    h_aux, w_aux, _ = tabla_recortada_aux.shape
    if x2 > w_aux or y2 > h_aux:
        raise ValueError(f"Las coordenadas de recorte están fuera de la tabla: ancho={w_aux}, alto={h_aux}")

    tabla_recortada = tabla_recortada_aux[y1:y2, x1:x2].copy()

    gray = cv2.cvtColor(tabla_recortada, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)
    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8), iterations=1)

    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 30))
    horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)
    vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)

    h_lines_extended = np.zeros_like(horizontal_lines)
    v_lines_extended = np.zeros_like(vertical_lines)
    alto_tabla, ancho_tabla = horizontal_lines.shape

    contours_h, _ = cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_h:
        x, y, w, h = cv2.boundingRect(cnt)
        y_center = y + h // 2
        cv2.line(h_lines_extended, (0, y_center), (ancho_tabla - 1, y_center), 255, 1)

    contours_v, _ = cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_v:
        x, y, w, h = cv2.boundingRect(cnt)
        x_center = x + w // 2
        cv2.line(v_lines_extended, (x_center, 0), (x_center, alto_tabla - 1), 255, 1)

    grid = cv2.bitwise_or(h_lines_extended, v_lines_extended)
    grid = cv2.dilate(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=5)
    grid = cv2.erode(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = np.vstack([grid, np.full((3, grid.shape[1]), 255, dtype=np.uint8)])

    contours_f, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours_f = [cnt for cnt in contours_f if cv2.contourArea(cnt) > 2500]
    sorted_cells_f = sort_cells(cell_contours_f)

    for idx, (cx, cy, cw, ch) in enumerate(sorted_cells_f):
        cv2.putText(tabla_recortada, str(idx), (cx+3, cy+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    cv2.drawContours(tabla_recortada, contours_f, -1, (0, 255, 0), 2)

    return grid, tabla_recortada, gray, sorted_cells_f, tabla_recortada_aux

def obtener_segunda_tabla(image, rotation=270):
    """
    Procesa una imagen para detectar y resaltar la cuadrícula de una tabla,
    realizando el recorte dinámicamente con base en los contornos detectados.

    Retorna:
        grid : imagen binaria de la cuadrícula detectada.
        t : imagen recortada de la tabla con celdas numeradas.
        gray : imagen en escala de grises de la tabla.
    """

    # Paso 1: Rotar la imagen 270° si es vertical
    image = image.rotate(rotation, expand=True)

    # Paso 3: Convertir a OpenCV y escala de grises
    image_cv = np.array(image)
    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)  # conversión correcta desde PIL a OpenCV
    gray_full = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)

    # Paso 4: Binarización invertida
    _, binary_image = cv2.threshold(gray_full, 150, 255, cv2.THRESH_BINARY_INV)

    # Paso 5: Buscar contornos grandes (tablas)
    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    table_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 100000]

    if not table_contours:
        print("No se encontró ninguna tabla.")
        return None, None, None

    # Paso 6: Tomar la tabla más grande
    main_contour = max(table_contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(main_contour)

    # Paso 7: Recortar desde la imagen rotada original
    tabla_recortada_aux = image_cv[y:y+h, x:x+w].copy()

    alto, ancho, _ = tabla_recortada_aux.shape

    '''plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(tabla_recortada_aux, cv2.COLOR_BGR2RGB))  # conversión BGR a RGB para mostrar bien en matplotlib
    plt.title("Tabla detectada (tabla_recortada_aux)")
    plt.axis("on")
    plt.show()'''

    # Recorte de una zona específica dentro de la tabla detectada automáticamente
    # Define tus límites relativos a la tabla detectada (no a la imagen original)
    x1, x2 = 530, 2100   # columnas (ancho)
    y1, y2 = 1550, 2100   # filas (alto)

    # Validación de coordenadas para evitar errores
    h_aux, w_aux, _ = tabla_recortada_aux.shape
    if x2 > w_aux or y2 > h_aux:
        raise ValueError(f"Las coordenadas de recorte están fuera de la tabla: ancho={w_aux}, alto={h_aux}")

    tabla_recortada = tabla_recortada_aux[y1:y2, x1:x2].copy()

    # Paso 8: Procesamiento de la tabla
    gray = cv2.cvtColor(tabla_recortada, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(gray, 255,
                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 15, 4)

    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8), iterations=1)

    # Paso 9: Extraer líneas horizontales y verticales
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 13))
    horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)
    vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)
    grid = cv2.bitwise_or(horizontal_lines, vertical_lines)

    # Paso 10: Mejorar cuadrícula
    grid = cv2.dilate(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=5)
    grid = cv2.erode(grid, np.ones((3, 3), np.uint8), iterations=1)

    # Paso 11: Agregar fila blanca artificial
    height, width = grid.shape
    white_row = np.full((3, width), 255, dtype=np.uint8)
    grid = np.vstack([grid, white_row])

    # Paso 12: Contornos de celdas
    contours_f, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours_f = [cnt for cnt in contours_f if cv2.contourArea(cnt) > 2500]

    # Ordenar celdas (asume función externa definida)
    sorted_cells_f = sort_cells(cell_contours_f)

    for idx, (cx, cy, cw, ch) in enumerate(sorted_cells_f):
        cv2.putText(tabla_recortada, str(idx), (cx+3, cy+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    cv2.drawContours(tabla_recortada, contours_f, -1, (0, 255, 0), 2)

    return grid, tabla_recortada, gray, sorted_cells_f

"""## Construccion tabla 1

Reduciendo filtros
"""

def construir_tabla_1_pandas(image, area_minima=2500, rotation=270):
    """
    Extrae texto de celdas específicas de una tabla y construye un DataFrame con nombres de columnas fijos
    y valores de celdas especificadas por índice. Aplica preprocesamiento morfológico individual por celda.

    Parámetros:
    - image: imagen de entrada (PIL o OpenCV)
    - area_minima: área mínima para filtrar celdas

    Retorna:
    - df: DataFrame con columnas definidas por el usuario
    """
    grid_f, t_f, gray_f, sorted_cells_f, _  = obtener_primera_tabla(image, rotation)
    columnas = {
        "TIPO DE RACIÓN": ["RI", "RPS", "CCT", "COMPLEMENTO", "TOTAL"],
        "N. RACIONES G. ETARIO A": [1, 7, 13, 19, 25],
        "N. RACIONES G. ETARIO B": [2, 8, 14, 20, 26],
        "N. RACIONES G. ETARIO C": [3, 9, 15, 21, 27],
        "N. RACIONES G. ETARIO D": [4, 10, 16, 22, 28],
        "N. RACIONES G. ETARIO E": [5, 11, 17, 23, 29],
        "TOTAL RACIONES": [6, 12, 18, 24, 30],
    }

    custom_config = r'--psm 6 -c tessedit_char_whitelist=0123456789'
    datos_columnas = {"TIPO DE RACIÓN": columnas["TIPO DE RACIÓN"]}

    for col, indices in columnas.items():
        if col == "TIPO DE RACIÓN":
            continue
        valores = []
        for idx in indices:
            if idx >= len(sorted_cells_f):
                valores.append(0)
                continue
            x, y, w, h = sorted_cells_f[idx]
            celda_img = gray_f[y+7:y+h-7, x+30:x+w-30]

            # --- 🔧 PREPROCESAMIENTO AVANZADO ---
            # 1. Suavizado (reduce ruido fino)
            #celda_img = cv2.medianBlur(celda_img, 3)
            celda_img = cv2.GaussianBlur(celda_img, (5, 5), 0)

            celda_bin = celda_img
            # 4. Operaciones morfológicas combinadas
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
            #celda_bin = cv2.erode(celda_bin, kernel, iterations=2)
            #celda_bin = cv2.morphologyEx(celda_bin, cv2.MORPH_CLOSE, kernel, iterations=2)
            #celda_bin = cv2.dilate(celda_bin, kernel, iterations=1)
            cv2_imshow(celda_bin) #Mostrar la celda transformada'''

            # --- OCR ---
            texto = pytesseract.image_to_string(celda_bin, config=custom_config)
            match = re.search(r'\b\d+\b', texto)
            valor = int(match.group()) if match else 0
            valores.append(valor)

        datos_columnas[col] = valores

    df = pd.DataFrame(datos_columnas)
    return df

"""## Construcción tabla 2"""

def construir_tabla_2_pandas(image, area_minima=2500, rotation=270):
    """
    Extrae texto de celdas específicas de una tabla y construye un DataFrame con nombres de columnas fijos
    y valores de celdas especificadas por índice. Aplica preprocesamiento morfológico individual por celda.

    Parámetros:
    - image: imagen de entrada (PIL o OpenCV)
    - area_minima: área mínima para filtrar celdas

    Retorna:
    - df: DataFrame con columnas definidas por el usuario
    """
    # Si la imagen es PIL, conviértela a formato OpenCV
    grid_f, t_f, gray_f, sorted_cells_f, = obtener_segunda_tabla(image, rotation)

    if sorted_cells_f is None:
        raise ValueError("No se pudieron detectar celdas en la tabla.")

    # Descripciones fijas
    col1 = "POBLACIÓN EN CONDICIÓN DE DISCAPACIDAD"
    col2 = "POBLACIÓN VÍCTIMA DEL CONFLICTO ARMADO"
    col3 = "COMUNIDADES ÉTNICAS"
    col4 = "POBLACIÓN MAYORITARIA"
    col5 = "GRAN TOTAL"

    columnas = {
        "DESCRIPCIÓN": [col1, col2, col3, col4, col5],
        "TOTAL RACIONES (RI)": [1, 6, 11, 16, 21],
        "TOTAL RACIONES (RPS)": [2, 7, 12, 17, 22],
        "TOTAL RACIONES (CCT)": [3, 8, 13, 18, 23],
        "TOTAL RACIONES (COMPLEMENTO)": [4, 9, 14, 19, 24],
        "N. TITULARES DE DERECHO": [5, 10, 15, 20, 25],
    }

    custom_config = r'--psm 6 -c tessedit_char_whitelist=0123456789'
    datos_columnas = {}

    for col, indices in columnas.items():
      # Si la columna es "DESCRIPCIÓN", no se aplica OCR. Ya tienes los textos directamente.
      if col == "DESCRIPCIÓN":
        datos_columnas[col] = indices
        continue
      valores = []
      for idx in indices:
          if idx >= len(sorted_cells_f):
              valores.append(0)
              continue
          x, y, w, h = sorted_cells_f[idx]
          celda_img = gray_f[y+7:y+h-7, x+20:x+w-20]

          # --- 🔧 PREPROCESAMIENTO AVANZADO ---
          # 1. Suavizado (reduce ruido fino)
          celda_img = cv2.GaussianBlur(celda_img, (5, 5), 1)

          celda_bin = celda_img
          # 2. Binarización adaptativa u Otsu
          _, celda_bin = cv2.threshold(celda_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

          # 4. Operaciones morfológicas combinadas
          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
          #celda_bin = cv2.erode(celda_bin, kernel, iterations=1)
          #celda_bin = cv2.morphologyEx(celda_bin, cv2.MORPH_CLOSE, kernel, iterations=1)
          #celda_bin = cv2.dilate(celda_bin, kernel, iterations=1) #Esta es la que he estado usando
          cv2_imshow(celda_bin) #Mostrar la celda transformada

          # --- OCR ---
          texto = pytesseract.image_to_string(celda_bin, config=custom_config)
          match = re.search(r'\b\d+\b', texto)
          valor = int(match.group()) if match else 0
          valores.append(valor)
      datos_columnas[col] = valores

    df = pd.DataFrame(datos_columnas)
    return df


"""# Conteo X

## Procesar símbolos
"""

def extract_central_symbol(image, umbral):
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    gray = cv2.GaussianBlur(gray, (5, 5), 1) ## Lo añadí yo
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    h, w = binary.shape
    img_center = np.array([w // 2, h // 2])

    center_radius = min(h, w) * 0.5
    min_area = 10

    selected_contours = []

    for cnt in contours:
        M = cv2.moments(cnt)
        if M['m00'] == 0:
            continue
        cx = int(M['m10'] / M['m00'])
        cy = int(M['m01'] / M['m00'])
        area = cv2.contourArea(cnt)
        dist = np.linalg.norm(np.array([cx, cy]) - img_center)

        if area > min_area or dist < center_radius:
            selected_contours.append(cnt)
    clean_mask = np.zeros_like(binary)
    cv2.drawContours(clean_mask, selected_contours, -1, 255, -1)

    cleaned = cv2.bitwise_and(binary, binary, mask=clean_mask)
    cleaned = cv2.bitwise_not(cleaned)

    center_patch = binary[h//3:h*2//3, w//3:w*2//3]
    if cv2.countNonZero(center_patch) < umbral:
      return 255 * np.ones_like(binary)

    return cleaned

"""## Obtener malla X"""

def get_best_grid_X_numbers(image):
  image = np.array(image)

  # 🔪 Recorte superior de 100 píxeles
  image = image[100:, :]

  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

  _, binary_image = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)
  contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

  table_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 140000]

  table = []

  for cont in table_contours:
    x, y, w, h = cv2.boundingRect(cont)
    table_image = image[y:y+h, x:x+w]
    cont = table_image
    table.append(cont)
    if not table:
        print(f"No table found on page {idx + 1}")
        idx += 1
        continue

  t = table[0]

  gray = cv2.cvtColor(t, cv2.COLOR_BGR2GRAY)
  binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)
  closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((4, 4), np.uint8), iterations=1)
  vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 17))
  vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)
  horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (68, 1))
  horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)
  horizontal_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 1))
  #horizontal_lines = cv2.morphologyEx(horizontal_lines, cv2.MORPH_CLOSE, horizontal_kernel_2, iterations=1)
  horizontal_kernel_3 = cv2.getStructuringElement(cv2.MORPH_RECT, (46, 1)) # 50?
  #horizontal_lines = cv2.morphologyEx(horizontal_lines, cv2.MORPH_OPEN, horizontal_kernel_3, iterations=2)


  grid = cv2.bitwise_or(horizontal_lines, vertical_lines)
  grid = cv2.dilate(grid, np.ones((3,3), np.uint8), iterations=1)
  grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((10, 10), np.uint8), iterations=5)
  grid_numbers = grid.copy()
  height, width = grid_numbers.shape
  cutoff_x_start = int(width * 1/37)
  cutoff_x = int(width * 36/37)
  subgrid = grid_numbers[:, cutoff_x_start:cutoff_x]
  vertical_cutoff = 200
  protected_top = subgrid[:vertical_cutoff, :]
  protected_top = np.full(protected_top.shape, 255, dtype=np.uint8)
  subgrid[:vertical_cutoff, :] = protected_top
  subgrid = subgrid[vertical_cutoff:, :]
  horizontal_kernel_subgrid = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 1))
  horizontal_closed_subgrid = cv2.morphologyEx(subgrid,
                                              cv2.MORPH_CLOSE,
                                              horizontal_kernel_subgrid,
                                              iterations=3)
  vertical_kernel_subgrid = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 17))
  aggressive_closing = cv2.morphologyEx(horizontal_closed_subgrid,
                                    cv2.MORPH_CLOSE,
                                    vertical_kernel_subgrid,
                                    iterations=2)
  subgrid_vert_closed = np.vstack([protected_top, aggressive_closing])
  blank_left = np.zeros((height, cutoff_x_start), dtype=np.uint8)
  subgrid_vert_closed = np.concatenate((blank_left, subgrid_vert_closed), axis=1)
  blank_right = np.zeros((height, width - cutoff_x), dtype=np.uint8)
  padded_aggressive = np.concatenate((subgrid_vert_closed, blank_right), axis=1)
  grid[:vertical_cutoff, :] = np.full((vertical_cutoff, grid.shape[1]), 255, dtype=np.uint8)
  grid = cv2.bitwise_or(grid, padded_aggressive)
  erode_kernel = np.ones((3, 3), np.uint8)
  grid = cv2.erode(grid, erode_kernel, iterations=1)
  white_row = np.full((3, width), 255, dtype=np.uint8)
  grid = np.vstack([grid, white_row])
  grid[:, :8] = 255
  grid[:, -6:] = 255

  return grid, t, gray

# Acá comienza la interfaz

"""# Streamlit"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit

import streamlit as st
import tempfile

# --- Interfaz ---
st.title("🧾 Extracción de Tablas desde PDF")

uploaded_file = st.file_uploader("Por favor, cargue su archivo PDF", type=["pdf"])

if uploaded_file:
    # Convertir PDF a imágenes
    with st.spinner("Convirtiendo PDF a imágenes..."):
        images = convert_from_bytes(uploaded_file.read())

    st.success(f"✅ Se extrajeron {len(images)} página(s)")

    # Permitir elegir una página
    page_index = st.number_input("Selecciona la página (comenzando desde 1)", min_value=1, max_value=len(images), step=1) - 1

    image = images[page_index]
    st.image(image, caption=f"Vista previa - Página {page_index + 1}", use_column_width=True)

    # Convertir a formato OpenCV
    image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

    if st.button("📊 Procesar tablas"):
        try:
            df1 = construir_tabla_1_pandas(image_cv)
            df2 = construir_tabla_2_pandas(image_cv)

            st.subheader("📋 Tabla 1")
            st.dataframe(df1)

            st.subheader("📋 Tabla 2")
            st.dataframe(df2)

            # Exportar como Excel opcional
            with st.expander("⬇ Descargar resultados"):
                with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmpfile:
                    with pd.ExcelWriter(tmpfile.name) as writer:
                        df1.to_excel(writer, sheet_name="Tabla1", index=False)
                        df2.to_excel(writer, sheet_name="Tabla2", index=False)
                    st.download_button("📥 Descargar Excel", data=open(tmpfile.name, 'rb').read(), file_name="tablas_extraidas.xlsx")
        except Exception as e:
            st.error(f"❌ Error al procesar: {e}")

