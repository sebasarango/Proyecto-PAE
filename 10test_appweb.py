# -*- coding: utf-8 -*-
"""10test_appweb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/165cvgDfoEkhuuoIjGh-avi81XU-bJF8X

# Instalaci√≥n de paquetes
"""

!pip install pdf2image
!apt-get install poppler-utils -y
!pip install pytesseract
!sudo apt update
!sudo apt install tesseract-ocr -y
!pip install easyocr

import re
import pytesseract
from pdf2image import convert_from_path
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
import easyocr

"""# Primera p√°gina

## Funciones para procesar como tabla:
"""

def sort_cells(cnts, vertical_thresh=30):

    bounding_boxes = [cv2.boundingRect(c) for c in cnts]
    bounding_boxes = sorted(bounding_boxes, key=lambda b: b[1])  # Ordena todos los bounding boxes por coordenada y (posici√≥n vertical), es decir, de arriba hacia abajo.

    rows = [] # rows: lista final con filas ordenadas
    current_row = [] # current_row: la fila que se est√° construyendo
    last_y = None #last_y: para comparar si una caja pertenece a la misma fila
    #threshold: tolerancia para decidir si dos cajas est√°n en la misma fila

    for box in bounding_boxes:
      #itera sobre cada bounding box ya ordenado por y.
        x, y, w, h = box
        if last_y is None:
            current_row.append(box)
            last_y = y
            continue
        if abs(y - last_y) < vertical_thresh: # Si la diferencia vertical es muy grande, se asume que es una nueva fila:
            current_row.append(box)
        else:
            rows.append(sorted(current_row, key=lambda b: b[0]))  # Se guarda la fila actual ordenada horizontalmente
            current_row = [box]

        last_y = y # Actualiza last_y con la posici√≥n de la celda actual.

    if current_row:
        rows.append(sorted(current_row, key=lambda b: b[0])) # a√±ade la √∫ltima fila construida (si existe).

    # Verificar resultado
    #print(f"Total filas detectadas: {len(rows)}")
    #for i, row in enumerate(rows):
     #   print(f"  Fila {i + 1}: {len(row)} celdas")

    return [cell for row in rows for cell in row] # Devuelve una lista "aplanada" con todas las celdas, ordenadas primero por fila, luego por columna.

"""## Auxiliares"""

# --- Agrupar l√≠neas similares ---
def agrupar_lineas_similares(lineas, tolerancia=15, orientacion="horizontal"):
    if not lineas:
        return []
    key = 1 if orientacion == "horizontal" else 0
    lineas = sorted(lineas, key=lambda l: l[0][key])
    agrupadas = []
    actual = lineas[0]

    for siguiente in lineas[1:]:
        if abs(siguiente[0][key] - actual[0][key]) < tolerancia:
            actual = np.vstack((actual, siguiente))
        else:
            agrupadas.append(actual)
            actual = siguiente

    agrupadas.append(actual)

    unificadas = []
    for grupo in agrupadas:
        grupo_np = np.array(grupo)
        xs = grupo_np[:, 0]
        ys = grupo_np[:, 1]
        x1, x2 = min(xs), max(xs)
        y1, y2 = min(ys), max(ys)
        if orientacion == "horizontal":
            unificadas.append([(x1, int(np.mean(ys))), (x2, int(np.mean(ys)))])
        else:
            unificadas.append([(int(np.mean(xs)), y1), (int(np.mean(xs)), y2)])

    return unificadas

# --- Filtrar l√≠neas con vecinas ---
def filtrar_lineas_con_vecinas(lineas, orientacion="horizontal", tolerancia=30, min_vecinas=1):
    if not lineas:
        return []
    resultado = []
    posiciones = [l[0][1] if orientacion == "horizontal" else l[0][0] for l in lineas]

    for i, linea in enumerate(lineas):
        pos = posiciones[i]
        vecinas = [1 for j, otra_pos in enumerate(posiciones) if i != j and abs(otra_pos - pos) < tolerancia]
        if len(vecinas) >= min_vecinas:
            resultado.append(linea)
    return resultado

# --- Validaci√≥n cruzada entre horizontales y verticales ---
def filtrar_lineas_cruzadas(horizontales, verticales, tolerancia=30):
    horizontales_validas = []
    verticales_validas = []

    for h in horizontales:
        (hx1, hy), (hx2, _) = h
        for v in verticales:
            (vx, vy1), (_, vy2) = v
            if (hx1 - tolerancia) <= vx <= (hx2 + tolerancia) and (vy1 <= hy <= vy2):
                horizontales_validas.append(h)
                break

    for v in verticales:
        (vx, vy1), (_, vy2) = v
        for h in horizontales:
            (hx1, hy), (hx2, _) = h
            if (hx1 <= vx <= hx2) and (vy1 - tolerancia <= hy <= vy2 + tolerancia):
                verticales_validas.append(v)
                break

    return horizontales_validas, verticales_validas

from sklearn.cluster import DBSCAN
import numpy as np

def detectar_cuadricula_densa(cell_boxes, eps=50, min_samples=10):
    """
    Agrupa celdas cercanas y detecta una posible tabla 5x5.

    cell_boxes: lista de (x, y, w, h) celdas
    eps: distancia m√°xima entre vecinos
    min_samples: m√≠nimo n√∫mero de celdas en el grupo

    Retorna:
        grupo_celdas: celdas que forman la tabla densa
        bbox: (x_min, y_min, x_max, y_max)
    """
    if len(cell_boxes) == 0:
        return [], None

    # Usar los centros de las celdas para agrupar
    centros = np.array([[x + w//2, y + h//2] for x, y, w, h in cell_boxes])
    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(centros)
    etiquetas = clustering.labels_

    grupos = {}
    for idx, etiqueta in enumerate(etiquetas):
        if etiqueta == -1:
            continue
        grupos.setdefault(etiqueta, []).append(cell_boxes[idx])

    mejor_grupo = []
    for g in grupos.values():
        if 20 <= len(g) <= 30:
            mejor_grupo = g
            break

    if not mejor_grupo:
        return [], None

    xs = [x for x, y, w, h in mejor_grupo] + [x + w for x, y, w, h in mejor_grupo]
    ys = [y for x, y, w, h in mejor_grupo] + [y + h for x, y, w, h in mejor_grupo]
    return mejor_grupo, (min(xs), min(ys), max(xs), max(ys))

"""## Obtener primera tabla, primera p√°gina"""

def obtener_primera_tabla(image, rotation=270):
    """
    Procesa una imagen para detectar y resaltar la cuadr√≠cula de una tabla,
    realizando el recorte din√°micamente con base en l√≠neas horizontales y verticales.

    Retorna:
        grid : imagen binaria de la cuadr√≠cula detectada.
        t : imagen recortada de la tabla con celdas numeradas.
        gray : imagen en escala de grises de la tabla.
        sorted_cells_f : celdas ordenadas (x, y, w, h).
    """
    image = image.rotate(rotation, expand=True)
    image_cv = np.array(image)
    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)
    gray_full = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)

    _, binary = cv2.threshold(gray_full, 150, 255, cv2.THRESH_BINARY_INV)
    bordes = cv2.Canny(binary, 50, 150, apertureSize=3)
    lineas = cv2.HoughLinesP(bordes, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=20)

    horizontales, verticales = [], []
    if lineas is not None:
        for linea in lineas:
            x1, y1, x2, y2 = linea[0]
            if abs(y2 - y1) < 15:
                horizontales.append([(x1, y1), (x2, y2)])
            elif abs(x2 - x1) < 15:
                verticales.append([(x1, y1), (x2, y2)])

    horizontales_f = filtrar_lineas_con_vecinas(horizontales, "horizontal", 30, 1)
    verticales_f = filtrar_lineas_con_vecinas(verticales, "vertical", 30, 1)

    horizontales_u = agrupar_lineas_similares(horizontales_f, orientacion="horizontal")
    verticales_u = agrupar_lineas_similares(verticales_f, orientacion="vertical")

    # üîÑ Extender horizontales al ancho detectado
    if verticales_u:
        xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
        left, right = min(xs), max(xs)
        horizontales_u = [[(left, y1), (right, y2)] for (x1, y1), (x2, y2) in horizontales_u]

    # üîÅ Validaci√≥n cruzada
    horizontales_u, verticales_u = filtrar_lineas_cruzadas(horizontales_u, verticales_u, 30)

    # üîÑ Extensi√≥n de verticales exteriores
    if verticales_u and horizontales_u:
        ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
        min_y = min(ys)
        max_y = max(ys)

        xs = [v[0][0] for v in verticales_u]
        min_x = min(xs)
        max_x = max(xs)

        verticales_extendidas = []
        for (x1, y1), (x2, y2) in verticales_u:
            if x1 == min_x or x1 == max_x:
                nueva_y1 = max(min_y - 100, 0)
                nueva_y2 = max_y + 100
                verticales_extendidas.append([(x1, nueva_y1), (x2, nueva_y2)])
            else:
                verticales_extendidas.append([(x1, y1), (x2, y2)])
        verticales_u = verticales_extendidas

    if not horizontales_u or not verticales_u:
        print("No se detect√≥ un contorno rectangular v√°lido.")
        return None, None, None, None

    ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
    xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
    top, bottom = min(ys), max(ys)
    left, right = min(xs), max(xs)

    tabla_recortada_aux = image_cv[top:bottom, left:right].copy()

    x1, x2 = 650, 1970
    y1, y2 = 950, 1400
    h_aux, w_aux, _ = tabla_recortada_aux.shape
    if x2 > w_aux or y2 > h_aux:
        raise ValueError(f"Las coordenadas de recorte est√°n fuera de la tabla: ancho={w_aux}, alto={h_aux}")

    tabla_recortada = tabla_recortada_aux[y1:y2, x1:x2].copy()
    gray = cv2.cvtColor(tabla_recortada, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)
    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8), iterations=1)

    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 30))
    horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)
    vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)

    h_lines_extended = np.zeros_like(horizontal_lines)
    v_lines_extended = np.zeros_like(vertical_lines)
    alto_tabla, ancho_tabla = horizontal_lines.shape

    contours_h, _ = cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_h:
        x, y, w, h = cv2.boundingRect(cnt)
        y_center = y + h // 2
        cv2.line(h_lines_extended, (0, y_center), (ancho_tabla - 1, y_center), 255, 1)

    contours_v, _ = cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_v:
        x, y, w, h = cv2.boundingRect(cnt)
        x_center = x + w // 2
        cv2.line(v_lines_extended, (x_center, 0), (x_center, alto_tabla - 1), 255, 1)

    grid = cv2.bitwise_or(h_lines_extended, v_lines_extended)
    grid = cv2.dilate(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=5)
    grid = cv2.erode(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = np.vstack([grid, np.full((3, grid.shape[1]), 255, dtype=np.uint8)])

    contours_f, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours_f = [cnt for cnt in contours_f if cv2.contourArea(cnt) > 2500]
    sorted_cells_f = sort_cells(cell_contours_f)

    grupo_denso, bbox = detectar_cuadricula_densa(sorted_cells_f)

    if grupo_denso:
        x1, y1, x2, y2 = bbox
        tabla_detectada = tabla_recortada[y1:y2, x1:x2]
        # Aqu√≠ puedes extraer solo esa tabla (la 5x5)

    for idx, (cx, cy, cw, ch) in enumerate(sorted_cells_f):
        cv2.putText(tabla_recortada, str(idx), (cx+3, cy+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    cv2.drawContours(tabla_recortada, contours_f, -1, (0, 255, 0), 2)

    return grid, tabla_recortada, gray, sorted_cells_f, tabla_recortada_aux

"""## Obtener segunda tabla, primera p√°gina

Incluir que calcule el n√∫mero de contornos y si no los encuentra, que aumente en X el valor
"""

def obtener_segunda_tabla(image, rotation=270):
    """
    Procesa una imagen para detectar y resaltar la cuadr√≠cula de una tabla,
    realizando el recorte din√°micamente con base en l√≠neas horizontales y verticales.

    Retorna:
        grid : imagen binaria de la cuadr√≠cula detectada.
        t : imagen recortada de la tabla con celdas numeradas.
        gray : imagen en escala de grises de la tabla.
        sorted_cells_f : celdas ordenadas (x, y, w, h).
    """
    image = image.rotate(rotation, expand=True)

    image_cv = np.array(image)
    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)
    gray_full = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)

    _, binary = cv2.threshold(gray_full, 150, 255, cv2.THRESH_BINARY_INV)
    bordes = cv2.Canny(binary, 50, 150, apertureSize=3)

    lineas = cv2.HoughLinesP(bordes, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=20)
    horizontales, verticales = [], []

    if lineas is not None:
        for linea in lineas:
            x1, y1, x2, y2 = linea[0]
            if abs(y2 - y1) < 15:
                horizontales.append([(x1, y1), (x2, y2)])
            elif abs(x2 - x1) < 15:
                verticales.append([(x1, y1), (x2, y2)])

    horizontales_f = filtrar_lineas_con_vecinas(horizontales, "horizontal", 30, 1)
    verticales_f = filtrar_lineas_con_vecinas(verticales, "vertical", 30, 1)

    horizontales_u = agrupar_lineas_similares(horizontales_f, orientacion="horizontal")
    verticales_u = agrupar_lineas_similares(verticales_f, orientacion="vertical")

    if verticales_u:
        xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
        left, right = min(xs), max(xs)
        horizontales_u = [[(left, y1), (right, y2)] for (x1, y1), (x2, y2) in horizontales_u]

    horizontales_u, verticales_u = filtrar_lineas_cruzadas(horizontales_u, verticales_u, 30)

    # üîÑ Extender l√≠neas verticales exteriores hacia arriba y abajo 100 p√≠xeles
    if verticales_u and horizontales_u:
        ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
        min_y = min(ys)
        max_y = max(ys)

        xs = [v[0][0] for v in verticales_u]
        min_x = min(xs)
        max_x = max(xs)

        verticales_extendidas = []
        for (x1, y1), (x2, y2) in verticales_u:
            if x1 == min_x or x1 == max_x:
                nueva_y1 = max(min_y - 100, 0)
                nueva_y2 = max_y + 100
                verticales_extendidas.append([(x1, nueva_y1), (x2, nueva_y2)])
            else:
                verticales_extendidas.append([(x1, y1), (x2, y2)])
        verticales_u = verticales_extendidas

    if not horizontales_u or not verticales_u:
        print("No se detect√≥ un contorno rectangular v√°lido.")
        return None, None, None, None

    ys = [p[0][1] for p in horizontales_u] + [p[1][1] for p in horizontales_u]
    xs = [p[0][0] for p in verticales_u] + [p[1][0] for p in verticales_u]
    top, bottom = min(ys), max(ys)
    left, right = min(xs), max(xs)

    tabla_recortada_aux = image_cv[top:bottom, left:right].copy()

    x1, x2 = 530, 2100   # columnas (ancho)
    y1, y2 = 1600, 2200   # filas (alto)

    h_aux, w_aux, _ = tabla_recortada_aux.shape
    if x2 > w_aux or y2 > h_aux:
        raise ValueError(f"Las coordenadas de recorte est√°n fuera de la tabla: ancho={w_aux}, alto={h_aux}")

    tabla_recortada = tabla_recortada_aux[y1:y2, x1:x2].copy()

    gray = cv2.cvtColor(tabla_recortada, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)
    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8), iterations=1)

    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 30))
    horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)
    vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)

    h_lines_extended = np.zeros_like(horizontal_lines)
    v_lines_extended = np.zeros_like(vertical_lines)
    alto_tabla, ancho_tabla = horizontal_lines.shape

    contours_h, _ = cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_h:
        x, y, w, h = cv2.boundingRect(cnt)
        y_center = y + h // 2
        cv2.line(h_lines_extended, (0, y_center), (ancho_tabla - 1, y_center), 255, 1)

    contours_v, _ = cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours_v:
        x, y, w, h = cv2.boundingRect(cnt)
        x_center = x + w // 2
        cv2.line(v_lines_extended, (x_center, 0), (x_center, alto_tabla - 1), 255, 1)

    grid = cv2.bitwise_or(h_lines_extended, v_lines_extended)
    grid = cv2.dilate(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=5)
    grid = cv2.erode(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = np.vstack([grid, np.full((3, grid.shape[1]), 255, dtype=np.uint8)])

    contours_f, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours_f = [cnt for cnt in contours_f if cv2.contourArea(cnt) > 2500]
    sorted_cells_f = sort_cells(cell_contours_f)

    for idx, (cx, cy, cw, ch) in enumerate(sorted_cells_f):
        cv2.putText(tabla_recortada, str(idx), (cx+3, cy+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    cv2.drawContours(tabla_recortada, contours_f, -1, (0, 255, 0), 2)

    return grid, tabla_recortada, gray, sorted_cells_f, tabla_recortada_aux

def obtener_segunda_tabla(image, rotation=270):
    """
    Procesa una imagen para detectar y resaltar la cuadr√≠cula de una tabla,
    realizando el recorte din√°micamente con base en los contornos detectados.

    Retorna:
        grid : imagen binaria de la cuadr√≠cula detectada.
        t : imagen recortada de la tabla con celdas numeradas.
        gray : imagen en escala de grises de la tabla.
    """

    # Paso 1: Rotar la imagen 270¬∞ si es vertical
    image = image.rotate(rotation, expand=True)

    # Paso 3: Convertir a OpenCV y escala de grises
    image_cv = np.array(image)
    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)  # conversi√≥n correcta desde PIL a OpenCV
    gray_full = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)

    # Paso 4: Binarizaci√≥n invertida
    _, binary_image = cv2.threshold(gray_full, 150, 255, cv2.THRESH_BINARY_INV)

    # Paso 5: Buscar contornos grandes (tablas)
    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    table_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 100000]

    if not table_contours:
        print("No se encontr√≥ ninguna tabla.")
        return None, None, None

    # Paso 6: Tomar la tabla m√°s grande
    main_contour = max(table_contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(main_contour)

    # Paso 7: Recortar desde la imagen rotada original
    tabla_recortada_aux = image_cv[y:y+h, x:x+w].copy()

    alto, ancho, _ = tabla_recortada_aux.shape

    '''plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(tabla_recortada_aux, cv2.COLOR_BGR2RGB))  # conversi√≥n BGR a RGB para mostrar bien en matplotlib
    plt.title("Tabla detectada (tabla_recortada_aux)")
    plt.axis("on")
    plt.show()'''

    # Recorte de una zona espec√≠fica dentro de la tabla detectada autom√°ticamente
    # Define tus l√≠mites relativos a la tabla detectada (no a la imagen original)
    x1, x2 = 530, 2100   # columnas (ancho)
    y1, y2 = 1550, 2100   # filas (alto)

    # Validaci√≥n de coordenadas para evitar errores
    h_aux, w_aux, _ = tabla_recortada_aux.shape
    if x2 > w_aux or y2 > h_aux:
        raise ValueError(f"Las coordenadas de recorte est√°n fuera de la tabla: ancho={w_aux}, alto={h_aux}")

    tabla_recortada = tabla_recortada_aux[y1:y2, x1:x2].copy()

    # Paso 8: Procesamiento de la tabla
    gray = cv2.cvtColor(tabla_recortada, cv2.COLOR_BGR2GRAY)
    binary = cv2.adaptiveThreshold(gray, 255,
                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 15, 4)

    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((2, 2), np.uint8), iterations=1)

    # Paso 9: Extraer l√≠neas horizontales y verticales
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 13))
    horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)
    vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)
    grid = cv2.bitwise_or(horizontal_lines, vertical_lines)

    # Paso 10: Mejorar cuadr√≠cula
    grid = cv2.dilate(grid, np.ones((3, 3), np.uint8), iterations=1)
    grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=5)
    grid = cv2.erode(grid, np.ones((3, 3), np.uint8), iterations=1)

    # Paso 11: Agregar fila blanca artificial
    height, width = grid.shape
    white_row = np.full((3, width), 255, dtype=np.uint8)
    grid = np.vstack([grid, white_row])

    # Paso 12: Contornos de celdas
    contours_f, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours_f = [cnt for cnt in contours_f if cv2.contourArea(cnt) > 2500]

    # Ordenar celdas (asume funci√≥n externa definida)
    sorted_cells_f = sort_cells(cell_contours_f)

    for idx, (cx, cy, cw, ch) in enumerate(sorted_cells_f):
        cv2.putText(tabla_recortada, str(idx), (cx+3, cy+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    cv2.drawContours(tabla_recortada, contours_f, -1, (0, 255, 0), 2)

    return grid, tabla_recortada, gray, sorted_cells_f

"""## Construccion tabla 1

Reduciendo filtros
"""

def construir_tabla_1_pandas(image, area_minima=2500, rotation=270):
    """
    Extrae texto de celdas espec√≠ficas de una tabla y construye un DataFrame con nombres de columnas fijos
    y valores de celdas especificadas por √≠ndice. Aplica preprocesamiento morfol√≥gico individual por celda.

    Par√°metros:
    - image: imagen de entrada (PIL o OpenCV)
    - area_minima: √°rea m√≠nima para filtrar celdas

    Retorna:
    - df: DataFrame con columnas definidas por el usuario
    """
    grid_f, t_f, gray_f, sorted_cells_f, _  = obtener_primera_tabla(image, rotation)
    columnas = {
        "TIPO DE RACI√ìN": ["RI", "RPS", "CCT", "COMPLEMENTO", "TOTAL"],
        "N. RACIONES G. ETARIO A": [1, 7, 13, 19, 25],
        "N. RACIONES G. ETARIO B": [2, 8, 14, 20, 26],
        "N. RACIONES G. ETARIO C": [3, 9, 15, 21, 27],
        "N. RACIONES G. ETARIO D": [4, 10, 16, 22, 28],
        "N. RACIONES G. ETARIO E": [5, 11, 17, 23, 29],
        "TOTAL RACIONES": [6, 12, 18, 24, 30],
    }

    custom_config = r'--psm 6 -c tessedit_char_whitelist=0123456789'
    datos_columnas = {"TIPO DE RACI√ìN": columnas["TIPO DE RACI√ìN"]}

    for col, indices in columnas.items():
        if col == "TIPO DE RACI√ìN":
            continue
        valores = []
        for idx in indices:
            if idx >= len(sorted_cells_f):
                valores.append(0)
                continue
            x, y, w, h = sorted_cells_f[idx]
            celda_img = gray_f[y+7:y+h-7, x+30:x+w-30]

            # --- üîß PREPROCESAMIENTO AVANZADO ---
            # 1. Suavizado (reduce ruido fino)
            #celda_img = cv2.medianBlur(celda_img, 3)
            celda_img = cv2.GaussianBlur(celda_img, (5, 5), 0)

            celda_bin = celda_img
            # 4. Operaciones morfol√≥gicas combinadas
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
            #celda_bin = cv2.erode(celda_bin, kernel, iterations=2)
            #celda_bin = cv2.morphologyEx(celda_bin, cv2.MORPH_CLOSE, kernel, iterations=2)
            #celda_bin = cv2.dilate(celda_bin, kernel, iterations=1)
            cv2_imshow(celda_bin) #Mostrar la celda transformada'''

            # --- OCR ---
            texto = pytesseract.image_to_string(celda_bin, config=custom_config)
            match = re.search(r'\b\d+\b', texto)
            valor = int(match.group()) if match else 0
            valores.append(valor)

        datos_columnas[col] = valores

    df = pd.DataFrame(datos_columnas)
    return df

"""## Construcci√≥n tabla 2"""

def construir_tabla_2_pandas(image, area_minima=2500, rotation=270):
    """
    Extrae texto de celdas espec√≠ficas de una tabla y construye un DataFrame con nombres de columnas fijos
    y valores de celdas especificadas por √≠ndice. Aplica preprocesamiento morfol√≥gico individual por celda.

    Par√°metros:
    - image: imagen de entrada (PIL o OpenCV)
    - area_minima: √°rea m√≠nima para filtrar celdas

    Retorna:
    - df: DataFrame con columnas definidas por el usuario
    """
    # Si la imagen es PIL, convi√©rtela a formato OpenCV
    grid_f, t_f, gray_f, sorted_cells_f, = obtener_segunda_tabla(image, rotation)

    if sorted_cells_f is None:
        raise ValueError("No se pudieron detectar celdas en la tabla.")

    # Descripciones fijas
    col1 = "POBLACI√ìN EN CONDICI√ìN DE DISCAPACIDAD"
    col2 = "POBLACI√ìN V√çCTIMA DEL CONFLICTO ARMADO"
    col3 = "COMUNIDADES √âTNICAS"
    col4 = "POBLACI√ìN MAYORITARIA"
    col5 = "GRAN TOTAL"

    columnas = {
        "DESCRIPCI√ìN": [col1, col2, col3, col4, col5],
        "TOTAL RACIONES (RI)": [1, 6, 11, 16, 21],
        "TOTAL RACIONES (RPS)": [2, 7, 12, 17, 22],
        "TOTAL RACIONES (CCT)": [3, 8, 13, 18, 23],
        "TOTAL RACIONES (COMPLEMENTO)": [4, 9, 14, 19, 24],
        "N. TITULARES DE DERECHO": [5, 10, 15, 20, 25],
    }

    custom_config = r'--psm 6 -c tessedit_char_whitelist=0123456789'
    datos_columnas = {}

    for col, indices in columnas.items():
      # Si la columna es "DESCRIPCI√ìN", no se aplica OCR. Ya tienes los textos directamente.
      if col == "DESCRIPCI√ìN":
        datos_columnas[col] = indices
        continue
      valores = []
      for idx in indices:
          if idx >= len(sorted_cells_f):
              valores.append(0)
              continue
          x, y, w, h = sorted_cells_f[idx]
          celda_img = gray_f[y+7:y+h-7, x+20:x+w-20]

          # --- üîß PREPROCESAMIENTO AVANZADO ---
          # 1. Suavizado (reduce ruido fino)
          celda_img = cv2.GaussianBlur(celda_img, (5, 5), 1)

          celda_bin = celda_img
          # 2. Binarizaci√≥n adaptativa u Otsu
          _, celda_bin = cv2.threshold(celda_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

          # 4. Operaciones morfol√≥gicas combinadas
          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
          #celda_bin = cv2.erode(celda_bin, kernel, iterations=1)
          #celda_bin = cv2.morphologyEx(celda_bin, cv2.MORPH_CLOSE, kernel, iterations=1)
          #celda_bin = cv2.dilate(celda_bin, kernel, iterations=1) #Esta es la que he estado usando
          cv2_imshow(celda_bin) #Mostrar la celda transformada

          # --- OCR ---
          texto = pytesseract.image_to_string(celda_bin, config=custom_config)
          match = re.search(r'\b\d+\b', texto)
          valor = int(match.group()) if match else 0
          valores.append(valor)
      datos_columnas[col] = valores

    df = pd.DataFrame(datos_columnas)
    return df

"""## Preprocesamiento de la imagen"""

import cv2
import numpy as np
import pytesseract

def preprocesar_celda_para_numeros(celda_img, metodo='mediana+otsu'):
    """
    Aplica diferentes t√©cnicas de preprocesamiento para mejorar el OCR en celdas con n√∫meros.

    Par√°metros:
    - celda_img: imagen en escala de grises de una celda
    - metodo: string con el nombre del m√©todo. Opciones:
        - 'mediana+otsu'
        - 'gaussiano+otsu'
        - 'bilateral+otsu'
        - 'morf_cierre'
        - 'morf_apertura'

    Retorna:
    - Imagen binarizada lista para OCR
    """

    if metodo == 'mediana+otsu':
        celda_img = cv2.medianBlur(celda_img, 3)
        _, celda_bin = cv2.threshold(celda_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    elif metodo == 'gaussiano+otsu':
        celda_img = cv2.GaussianBlur(celda_img, (5, 5), 0)
        _, celda_bin = cv2.threshold(celda_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    elif metodo == 'bilateral+otsu':
        celda_img = cv2.bilateralFilter(celda_img, 9, 75, 75)
        _, celda_bin = cv2.threshold(celda_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    elif metodo == 'morf_cierre':
        kernel = np.ones((2, 2), np.uint8)
        celda_bin = cv2.morphologyEx(celda_img, cv2.MORPH_CLOSE, kernel)

    elif metodo == 'morf_apertura':
        kernel = np.ones((2, 2), np.uint8)
        celda_bin = cv2.morphologyEx(celda_img, cv2.MORPH_OPEN, kernel)

    else:
        raise ValueError("M√©todo no reconocido. Prueba con 'mediana+otsu', 'gaussiano+otsu', etc.")

    return celda_bin

"""# Ejemplos"""

# cargar archivos pdf con files
from google.colab import files

# Cargar archivo PDF
pdf = files.upload()
pdf_path = next(iter(pdf))  # Obtiene el nombre del primer archivo

# Convertir PDF a im√°genes
pages = convert_from_path(pdf_path, dpi=300)

# Convertir la primera p√°gina a formato OpenCV (opcional)
image = pages[0]
#image_cv = np.array(image)

"""# Tablas resultados

### Primera tabla
"""

rotation = 270
_, t , _, _, a = obtener_primera_tabla(image, rotation=rotation)
cv2_imshow(t)

df_raciones = construir_tabla_1_pandas(image, rotation=rotation)
df_raciones

"""### Segunda tabla."""

grid, t , _, _ ,= obtener_segunda_tabla(image, rotation=rotation)
cv2_imshow(t)

df_raciones_2 = construir_tabla_2_pandas(image, rotation=rotation)
df_raciones_2

"""# Conteo X

## Procesar s√≠mbolos
"""

def extract_central_symbol(image, umbral):
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    gray = cv2.GaussianBlur(gray, (5, 5), 1) ## Lo a√±ad√≠ yo
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    h, w = binary.shape
    img_center = np.array([w // 2, h // 2])

    center_radius = min(h, w) * 0.5
    min_area = 10

    selected_contours = []

    for cnt in contours:
        M = cv2.moments(cnt)
        if M['m00'] == 0:
            continue
        cx = int(M['m10'] / M['m00'])
        cy = int(M['m01'] / M['m00'])
        area = cv2.contourArea(cnt)
        dist = np.linalg.norm(np.array([cx, cy]) - img_center)

        if area > min_area or dist < center_radius:
            selected_contours.append(cnt)
    clean_mask = np.zeros_like(binary)
    cv2.drawContours(clean_mask, selected_contours, -1, 255, -1)

    cleaned = cv2.bitwise_and(binary, binary, mask=clean_mask)
    cleaned = cv2.bitwise_not(cleaned)

    center_patch = binary[h//3:h*2//3, w//3:w*2//3]
    if cv2.countNonZero(center_patch) < umbral:
      return 255 * np.ones_like(binary)

    return cleaned

"""## Obtener malla X"""

def get_best_grid_X_numbers(image):
  image = np.array(image)

  # üî™ Recorte superior de 100 p√≠xeles
  image = image[100:, :]

  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

  _, binary_image = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)
  contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

  table_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 140000]

  table = []

  for cont in table_contours:
    x, y, w, h = cv2.boundingRect(cont)
    table_image = image[y:y+h, x:x+w]
    cont = table_image
    table.append(cont)
    if not table:
        print(f"No table found on page {idx + 1}")
        idx += 1
        continue

  t = table[0]

  gray = cv2.cvtColor(t, cv2.COLOR_BGR2GRAY)
  binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)
  closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, np.ones((4, 4), np.uint8), iterations=1)
  vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 17))
  vertical_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, vertical_kernel, iterations=3)
  horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (68, 1))
  horizontal_lines = cv2.morphologyEx(closed, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)
  horizontal_kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 1))
  #horizontal_lines = cv2.morphologyEx(horizontal_lines, cv2.MORPH_CLOSE, horizontal_kernel_2, iterations=1)
  horizontal_kernel_3 = cv2.getStructuringElement(cv2.MORPH_RECT, (46, 1)) # 50?
  #horizontal_lines = cv2.morphologyEx(horizontal_lines, cv2.MORPH_OPEN, horizontal_kernel_3, iterations=2)


  grid = cv2.bitwise_or(horizontal_lines, vertical_lines)
  grid = cv2.dilate(grid, np.ones((3,3), np.uint8), iterations=1)
  grid = cv2.morphologyEx(grid, cv2.MORPH_CLOSE, np.ones((10, 10), np.uint8), iterations=5)
  grid_numbers = grid.copy()
  height, width = grid_numbers.shape
  cutoff_x_start = int(width * 1/37)
  cutoff_x = int(width * 36/37)
  subgrid = grid_numbers[:, cutoff_x_start:cutoff_x]
  vertical_cutoff = 200
  protected_top = subgrid[:vertical_cutoff, :]
  protected_top = np.full(protected_top.shape, 255, dtype=np.uint8)
  subgrid[:vertical_cutoff, :] = protected_top
  subgrid = subgrid[vertical_cutoff:, :]
  horizontal_kernel_subgrid = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 1))
  horizontal_closed_subgrid = cv2.morphologyEx(subgrid,
                                              cv2.MORPH_CLOSE,
                                              horizontal_kernel_subgrid,
                                              iterations=3)
  vertical_kernel_subgrid = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 17))
  aggressive_closing = cv2.morphologyEx(horizontal_closed_subgrid,
                                    cv2.MORPH_CLOSE,
                                    vertical_kernel_subgrid,
                                    iterations=2)
  subgrid_vert_closed = np.vstack([protected_top, aggressive_closing])
  blank_left = np.zeros((height, cutoff_x_start), dtype=np.uint8)
  subgrid_vert_closed = np.concatenate((blank_left, subgrid_vert_closed), axis=1)
  blank_right = np.zeros((height, width - cutoff_x), dtype=np.uint8)
  padded_aggressive = np.concatenate((subgrid_vert_closed, blank_right), axis=1)
  grid[:vertical_cutoff, :] = np.full((vertical_cutoff, grid.shape[1]), 255, dtype=np.uint8)
  grid = cv2.bitwise_or(grid, padded_aggressive)
  erode_kernel = np.ones((3, 3), np.uint8)
  grid = cv2.erode(grid, erode_kernel, iterations=1)
  white_row = np.full((3, width), 255, dtype=np.uint8)
  grid = np.vstack([grid, white_row])
  grid[:, :8] = 255
  grid[:, -6:] = 255

  return grid, t, gray

grid, t, _ = get_best_grid_X_numbers(images[1])
contours, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

cell_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 900]
cv2.drawContours(t, cell_contours, -1, (0, 255, 0), 2)
cv2_imshow(t)

"""## Procesamiento"""

custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789'
reader = easyocr.Reader(['en'])
sum=0
idx=0

data_by_page = []
CELLS_PER_ROW = 37
START_INDEX = 13
page_rows = []
cur_page = 1

#images = convert_from_path(pdf_file_path, dpi=300)
for image in pages:
  if cur_page == 0 or cur_page== 1:
    cur_page = 2
    continue

  grid, t, gray = get_best_grid_X_numbers(image)
  #cv2_imshow(grid)

  print('Processing page {}'.format(cur_page))

  contours, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
  cell_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 900]

  sorted_cells = sort_cells(cell_contours)

  page_number = idx + 1
  page_rows = []

  for i, (x, y, w, h) in enumerate(sorted_cells):
    offset = 1
    if i >= offset:
      relative_idx = i - offset
      row_num = relative_idx // CELLS_PER_ROW
      col_num = relative_idx % CELLS_PER_ROW
      if col_num in range(2, 7):
        adjustment_h = 10
        adjustment_v = 2
        main_cell = gray[y-adjustment_h:y+h-adjustment_h, x-adjustment_h:x+w-adjustment_h]
      else:
        adjustment_h_symbols = 5
        adjustment_v = 5
        main_cell = gray[y-adjustment_v:y+h-adjustment_v, x-adjustment_h_symbols:x+w-adjustment_h_symbols]

      non_zero_pixels = main_cell.size - cv2.countNonZero(main_cell)
      extracted_text = None

      if col_num >= START_INDEX:
        theX = extract_central_symbol(main_cell)
        non_zero_pixels_theX = theX.size - cv2.countNonZero(theX)
        while len(page_rows) <= row_num:
          page_rows.append([])

        if col_num == CELLS_PER_ROW - 1:
          page_rows[row_num].append(None)
        else:
          page_rows[row_num].append(non_zero_pixels_theX)

      cv2.rectangle(t, (x, y), (x+w, y+h), (255, 0, 0), 2)


  page_df = pd.DataFrame(page_rows)
  page_df.index = [f"Page_{page_number}_Row_{i+1}" for i in range(len(page_df))]
  data_by_page.append(page_df)
  idx += 1

  #cv2.drawContours(t, cell_contours, -1, (0, 255, 0), 2)
  #cv2_imshow(t)
  #print()
  #cv2.waitKey(0)
  #cv2.destroyAllWindows()
  cur_page += 1
full_df = pd.concat(data_by_page)

"""# Estad√≠sticas"""

non_zero_vals = full_df.loc[:, 0:22].stack()
non_zero_vals = non_zero_vals[non_zero_vals != 0]
min_non_zero = non_zero_vals.min() if not non_zero_vals.empty else None
min_non_zero

X_df = full_df.loc[:,0:22]
X_df['row_sum'] = (X_df >= min_non_zero).sum(axis=1)
global_count = X_df['row_sum'].sum()
print(global_count)

resumen_df = X_df.copy()
# cuenta los valores unicos de la tabla resumen_df en la columna 'row_sum'
resumen_df['row_sum'].value_counts()

resumen_df = X_df.copy()
# cuenta los valores unicos de la tabla resumen_df en la columna 'row_sum'
resumen_df['row_sum'].value_counts()

resumen_df[resumen_df['row_sum'] != resumen_df['row_sum'].mode()[0]]['row_sum']

resumen_df[resumen_df['row_sum']==23]['row_sum']

# P√°gina a visualizar (ej. p√°gina 5 del PDF)
page_number = 18
image = pages[page_number - 1]

# Convertir a formato OpenCV
image_cv = np.array(image)

# Obtener tabla y grilla desde esa p√°gina (usa tu funci√≥n personalizada)
grid, t, gray = get_best_grid_X_numbers(image)

# Detectar contornos sobre la grilla
contours, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

# Dibujar los contornos sobre la imagen de la tabla detectada
t_with_contours = t.copy()
cv2.drawContours(t_with_contours, contours, -1, (0, 255, 0), 2)

# Mostrar usando matplotlib (si est√°s fuera de Colab)
plt.figure(figsize=(12, 14))
plt.imshow(cv2.cvtColor(t_with_contours, cv2.COLOR_BGR2RGB))
plt.title(f"Contornos en p√°gina {page_number}")
plt.axis('off')
plt.show()

total_delivered = 17457
print(f"Las raciones reportadas en la primera p√°gina {'' if global_count == int(total_delivered) else 'no'} coinciden con las marcaciones registradas en el documento.")
print(f"Se reportaron {int(total_delivered)} en la primera p√°gina. Se encontraron {global_count} marcaciones.")
difference = abs(int(total_delivered) - global_count)
print(f"Diferencia: {difference}")
den = max(int(total_delivered), global_count)
print(f"M√°ximo valor: {den}")
print(f"Porcentaje de fallo: {((difference) / den) * 100}%")
print(f"Las raciones reportadas en la primera p√°gina {'' if global_count == int(total_delivered) else 'no'} coinciden con las marcaciones registradas en el documento.")
print(f"Se reportaron {int(total_delivered)} en la primera p√°gina. Se encontraron {global_count} marcaciones.")
difference = abs(int(total_delivered) - global_count)
print(f"Diferencia: {difference}")
den = max(int(total_delivered), global_count)
print(f"M√°ximo valor: {den}")
print(f"Porcentaje de fallo: {((difference) / den) * 100}%")
total_aprox = 1587*11
print(f"Porcentaje de aciertos: {(1 - (difference / den)) * 100}%")
print(f"Porcentaje de x encontradas frente al total de raciones estimadas: {(global_count/total_aprox)* 100:.3f}%")

"""# Otro conteo"""

pages = pages[2:4]

def extract_central_symbol(image, umbral, border_crop=8):
    """
    Extrae el s√≠mbolo de una celda eliminando los m√°rgenes, y muestra en consola
    el porcentaje de p√≠xeles oscuros como indicador de presencia.

    Retorna:
        Imagen binaria con s√≠mbolo (fondo blanco).
    """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    # Recorte de m√°rgenes
    h, w = gray.shape
    crop_x1 = border_crop
    crop_y1 = border_crop
    crop_x2 = w - border_crop
    crop_y2 = h - border_crop
    cv2_imshow(gray)
    if crop_x2 <= crop_x1 or crop_y2 <= crop_y1:
        cv2_imshow(gray)
        print("‚ö†Ô∏è Recorte inv√°lido ‚Äî celda vac√≠a.")
        return 255 * np.ones_like(gray)

    cropped = gray[crop_y1:crop_y2, crop_x1:crop_x2]

    # Binarizaci√≥n
    cropped = cv2.GaussianBlur(cropped, (5, 5), 1)
    _, binary = cv2.threshold(cropped, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    #cv2_imshow(binary)

    # Contornos relevantes
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_center = np.array([binary.shape[1] // 2, binary.shape[0] // 2])
    center_radius = min(binary.shape[:2]) * 0.5
    min_area = 10

    selected_contours = []
    for cnt in contours:
        M = cv2.moments(cnt)
        if M['m00'] == 0:
            continue
        cx = int(M['m10'] / M['m00'])
        cy = int(M['m01'] / M['m00'])
        area = cv2.contourArea(cnt)
        dist = np.linalg.norm(np.array([cx, cy]) - img_center)

        if area > min_area or dist < center_radius:
            selected_contours.append(cnt)

    # M√°scara limpia
    clean_mask = np.zeros_like(binary)
    cv2.drawContours(clean_mask, selected_contours, -1, 255, -1)

    cleaned = cv2.bitwise_and(binary, binary, mask=clean_mask)
    cleaned = cv2.bitwise_not(cleaned)

    # C√°lculo de densidad de p√≠xeles oscuros
    total_pixels = cleaned.size
    dark_pixels = total_pixels - cv2.countNonZero(cleaned)
    density = dark_pixels / total_pixels

    #print(f"Densidad de p√≠xeles oscuros: {density:.3f} ({dark_pixels} de {total_pixels})")

    if dark_pixels < umbral:
        return 255 * np.ones_like(cleaned)

    return cleaned

sum = 0              # Acumulador (no usado en este fragmento)
idx = 0              # √çndice de p√°gina procesada
data_by_page = []    # Lista de DataFrames por p√°gina

CELLS_PER_ROW = 37   # N√∫mero esperado de celdas por fila en la tabla
START_INDEX = 13     # A partir de esta columna se empieza a procesar contenido
page_rows = []       # Contenedor temporal para cada fila de una p√°gina

cur_page = 1         # Control del n√∫mero de p√°gina
START_INDEX = 13
cut_x_positions = []  # Guardar√° todos los x de la columna 13

umbral = 100
border_crop = 8

for image in pages:
    if cur_page <= 1:
        cur_page += 1
        continue

    grid, t, gray = get_best_grid_X_numbers(image)
    print('Processing page {}'.format(cur_page))

    contours, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 4000]
    #for cnt in contours:
      #print(cv2.contourArea(cnt))
    sorted_cells = sort_cells(cell_contours)

    page_number = idx + 1
    page_rows = []

    for i, (x, y, w, h) in enumerate(sorted_cells):
        offset = 1
        if i >= offset:
            relative_idx = i - offset
            row_num = relative_idx // CELLS_PER_ROW
            col_num = relative_idx % CELLS_PER_ROW

            # Recolectar coordenadas x para columna 13
            if col_num == START_INDEX:
                cut_x_positions.append(x)

            if col_num >= START_INDEX:
                adjustment_h = 10 if col_num in range(2, 7) else 5
                adjustment_v = 2 if col_num in range(2, 7) else 5
                main_cell = gray[y-adjustment_v:y+h-adjustment_v, x-adjustment_h:x+w-adjustment_h]
                theX = extract_central_symbol(main_cell, umbral, border_crop)
                #cv2_imshow(theX)
                non_zero_pixels_theX = theX.size - cv2.countNonZero(theX)

                while len(page_rows) <= row_num:
                    page_rows.append([])

                page_rows[row_num].append(non_zero_pixels_theX if col_num != CELLS_PER_ROW - 1 else None)
            cv2.rectangle(t, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # Calcular corte robusto
    if cut_x_positions:
        cut_x_start = int(median(cut_x_positions))
        t = t[:, cut_x_start:]
        gray = gray[:, cut_x_start:]
        grid = grid[:, cut_x_start:]

    page_df = pd.DataFrame(page_rows)
    page_df.index = [f"Page_{page_number}_Row_{i+1}" for i in range(len(page_df))]
    page_df.columns = [f"C{START_INDEX + j}" for j in range(page_df.shape[1])]
    data_by_page.append(page_df)
    idx += 1
    #cv2.drawContours(t, cell_contours, -1, (0, 255, 0), 2)
    cv2_imshow(t)
    cur_page += 1

full_df = pd.concat(data_by_page)

from statistics import median

sum = 0
idx = 0
data_by_page = []

CELLS_PER_ROW = 37
page_rows = []
cur_page = 1
cut_x_positions = []

umbral = 100
border_crop = 1

for image in pages:
    if cur_page <= 1:
        cur_page += 1
        continue

    grid, t, gray = get_best_grid_X_numbers(image)
    print('üîÑ Processing page {}'.format(cur_page))

    # --- Primera pasada: obtener coordenadas x de la columna 13 ---
    contours_tmp, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours_tmp = [cnt for cnt in contours_tmp if cv2.contourArea(cnt) > 4000]
    sorted_cells_tmp = sort_cells(cell_contours_tmp)

    for i, (x, y, w, h) in enumerate(sorted_cells_tmp):
        offset = 1
        if i >= offset:
            relative_idx = i - offset
            col_num = relative_idx % CELLS_PER_ROW
            if col_num == 13:
                cut_x_positions.append(x)

    # --- Aplicar el corte antes de seguir ---
    if cut_x_positions:
        cut_x_start = int(median(cut_x_positions))
        t = t[:, cut_x_start:]
        gray = gray[:, cut_x_start-5:]
        grid = grid[:, cut_x_start-5:]
        # Agregar l√≠nea vertical artificial en el borde izquierdo (x=0)

        altura = grid.shape[0]
        #cv2.line(grid, (0, 0), (0, altura), 255, 3)  # L√≠nea blanca vertical de 2 px de grosor
        #cv2.line(grid, (0, 0), (1500, 0), 255, 3)  # L√≠nea horizontal superior

    # --- Segunda pasada: procesar sobre imagen recortada ---
    contours, _ = cv2.findContours(grid, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cell_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 4000]
    sorted_cells = sort_cells(cell_contours)

    page_number = idx + 1
    page_rows = []

    for i, (x, y, w, h) in enumerate(sorted_cells):
        offset = 1
        if i >= offset:
            relative_idx = i - offset
            row_num = relative_idx // CELLS_PER_ROW
            col_num = relative_idx % CELLS_PER_ROW  # ¬°Ahora empieza en 0 despu√©s del corte!

            # üí° Extraer desde la PRIMERA columna posterior al corte
            if col_num >= 0:
                adjustment_h = 10 if col_num in range(2, 7) else 5
                adjustment_v = 2 if col_num in range(2, 7) else 5
                main_cell = gray[y-adjustment_v:y+h-adjustment_v,
                                 x-adjustment_h:x+w-adjustment_h]

                theX = extract_central_symbol(main_cell, umbral, border_crop)
                cv2_imshow(theX)
                non_zero_pixels_theX = theX.size - cv2.countNonZero(theX)

                while len(page_rows) <= row_num:
                    page_rows.append([])

                page_rows[row_num].append(non_zero_pixels_theX if col_num != CELLS_PER_ROW - 1 else None)

            cv2.rectangle(t, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # Construcci√≥n del DataFrame
    page_df = pd.DataFrame(page_rows)
    page_df.index = [f"Page_{page_number}_Row_{i+1}" for i in range(len(page_df))]
    page_df.columns = [f"C{j}" for j in range(page_df.shape[1])]  # Comenzamos en C0 ahora
    data_by_page.append(page_df)

    idx += 1
    cv2.drawContours(t, cell_contours, -1, (0, 255, 0), 2)
    cv2_imshow(grid)
    cur_page += 1

# Unir todas las p√°ginas
full_df = pd.concat(data_by_page)

# Recalculate global count
X_df = full_df.loc[:, [f'C{i}' for i in range(START_INDEX, START_INDEX + 23)]]
X_df['row_sum'] = (X_df >= min_non_zero).sum(axis=1)
global_count = X_df['row_sum'].sum()
print(global_count)

# Access columns using their string names
non_zero_vals = full_df.loc[:, [f'C{i}' for i in range(START_INDEX, START_INDEX + 23)]].stack()
non_zero_vals = non_zero_vals[non_zero_vals != 0]
min_non_zero = non_zero_vals.min() if not non_zero_vals.empty else None
min_non_zero

resumen_df = X_df.copy()
# cuenta los valores unicos de la tabla resumen_df en la columna 'row_sum'
resumen_df['row_sum'].value_counts()

resumen_df['row_sum']

resumen_df[resumen_df['row_sum'] != resumen_df['row_sum'].mode()[0]]['row_sum']

# Assuming total_delivered is obtained from the first page of the PDF and stored in a variable.
# If not already defined, please define total_delivered
# For example:
total_delivered = df_raciones['TOTAL RACIONES'][4] # Assuming the total is in the last row of 'TOTAL RACIONES' column in df_raciones

print(f"Las raciones reportadas en la primera p√°gina {'' if global_count == int(total_delivered) else 'no'} coinciden con las marcaciones registradas en el documento.")
print(f"Se reportaron {int(total_delivered)} en la primera p√°gina. Se encontraron {global_count} marcaciones.")
difference = abs(int(total_delivered) - global_count)
print(f"Diferencia: {difference}")
den = max(int(total_delivered), global_count)
print(f"M√°ximo valor: {den}")
print(f"Porcentaje de fallo: {((difference) / den) * 100}%")
print(f"Las raciones reportadas en la primera p√°gina {'' if global_count == int(total_delivered) else 'no'} coinciden con las marcaciones registradas en el documento.")
print(f"Se reportaron {int(total_delivered)} en la primera p√°gina. Se encontraron {global_count} marcaciones.")
difference = abs(int(total_delivered) - global_count)
print(f"Diferencia: {difference}")
den = max(int(total_delivered), global_count)
print(f"M√°ximo valor: {den}")
print(f"Porcentaje de fallo: {((difference) / den) * 100}%")
# Assuming total_aprox is an estimated total from the document structure or context
# If not already defined, please define total_aprox
# For example:
total_aprox = 1587*11 # Replace with the actual calculation if different
print(f"Porcentaje de aciertos: {(1 - (difference / den)) * 100}%")
print(f"Porcentaje de x encontradas frente al total de raciones estimadas: {(global_count/total_aprox)* 100:.3f}%")

"""# Streamlit"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit

import streamlit as st
import tempfile

# --- Interfaz ---
st.title("üßæ Extracci√≥n de Tablas desde PDF")

uploaded_file = st.file_uploader("Por favor, cargue su archivo PDF", type=["pdf"])

if uploaded_file:
    # Convertir PDF a im√°genes
    with st.spinner("Convirtiendo PDF a im√°genes..."):
        images = convert_from_bytes(uploaded_file.read())

    st.success(f"‚úÖ Se extrajeron {len(images)} p√°gina(s)")

    # Permitir elegir una p√°gina
    page_index = st.number_input("Selecciona la p√°gina (comenzando desde 1)", min_value=1, max_value=len(images), step=1) - 1

    image = images[page_index]
    st.image(image, caption=f"Vista previa - P√°gina {page_index + 1}", use_column_width=True)

    # Convertir a formato OpenCV
    image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

    if st.button("üìä Procesar tablas"):
        try:
            df1 = construir_tabla_1_pandas(image_cv)
            df2 = construir_tabla_2_pandas(image_cv)

            st.subheader("üìã Tabla 1")
            st.dataframe(df1)

            st.subheader("üìã Tabla 2")
            st.dataframe(df2)

            # Exportar como Excel opcional
            with st.expander("‚¨á Descargar resultados"):
                with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmpfile:
                    with pd.ExcelWriter(tmpfile.name) as writer:
                        df1.to_excel(writer, sheet_name="Tabla1", index=False)
                        df2.to_excel(writer, sheet_name="Tabla2", index=False)
                    st.download_button("üì• Descargar Excel", data=open(tmpfile.name, 'rb').read(), file_name="tablas_extraidas.xlsx")
        except Exception as e:
            st.error(f"‚ùå Error al procesar: {e}")

